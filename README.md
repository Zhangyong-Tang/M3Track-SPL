# M3Track: Meta-Prompt for Multi-Modal Tracking

This work is accepted by IEEE Signal Processing Letter in 20250323.

![6f7e9ff5939908ed2da185f9f8f4fb9](https://github.com/user-attachments/assets/3c5360d3-88e0-4861-bf06-377a66b4a372)

‚≠ê We carefully design a dedicated meta-prompt learning solution in the realm of multi-modal tracking, injecting sequence-specific evidence through online adaption. 

‚≠ê We propose a unified multi-modal tracker without the prerequisite of feeding any task priors (notification of task type) in both training and test phases.

![image](https://github.com/user-attachments/assets/82373e32-5c58-4341-929c-2f886523751f)


‚≠ê This work brings limited degradation on efficiency but consistent improvements

![image](https://github.com/user-attachments/assets/1a5507df-f247-4561-9bca-f8cf3543517c)


‚≠ê Visiualisation

![image](https://github.com/user-attachments/assets/cae705e1-51c8-4c09-a3a7-ba70991360fd)


üîΩ Please follow ViPT[https://github.com/jiawen-zhu/ViPT] to create your conda environment.


